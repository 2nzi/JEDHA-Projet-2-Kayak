{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Yelp\n",
    "\n",
    "The aim of this exercise is to allow a user to make an automatic search on <a href=\"https://www.yelp.fr/\" target=\"_blank\">Yelp</a> and store the results in a `.json` file. You will be guided through the different steps: making a form request with search keywords, parsing the search results, crawling all the result pages and storing the results into a file.\n",
    "\n",
    "âš  **As scrapy is not made to launch several crawler processes in the same script, you will have to restart your notebook's kernel before completing each question!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached Scrapy-2.11.1-py2.py3-none-any.whl (287 kB)\n",
      "Collecting protego>=0.1.15\n",
      "  Using cached Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting queuelib>=1.4.2\n",
      "  Using cached queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting pyOpenSSL>=21.0.0\n",
      "  Using cached pyOpenSSL-24.1.0-py3-none-any.whl (56 kB)\n",
      "Collecting zope.interface>=5.1.0\n",
      "  Using cached zope.interface-6.2-cp38-cp38-win_amd64.whl (204 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from scrapy) (24.0)\n",
      "Collecting Twisted>=18.9.0\n",
      "  Using cached twisted-24.3.0-py3-none-any.whl (3.2 MB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Using cached w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Using cached itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Collecting tldextract\n",
      "  Using cached tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Using cached itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting lxml>=4.4.1\n",
      "  Using cached lxml-5.1.0-cp38-cp38-win_amd64.whl (3.9 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from scrapy) (56.0.0)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Using cached cryptography-42.0.5-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Using cached parsel-1.9.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting service-identity>=18.1.0\n",
      "  Using cached service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Using cached cffi-1.16.0-cp38-cp38-win_amd64.whl (181 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting pyasn1-modules\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Collecting attrs>=19.1.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Collecting pyasn1\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting incremental>=22.10.0\n",
      "  Using cached incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting automat>=0.8.0\n",
      "  Using cached Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.10.0)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2\n",
      "  Using cached twisted_iocpsupport-1.0.4-cp38-cp38-win_amd64.whl (47 kB)\n",
      "Collecting constantly>=15.1\n",
      "  Using cached constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (3.6)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4\n",
      "  Using cached requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting filelock>=3.0.8\n",
      "  Using cached filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\antoi\\documents\\work&learn\\jedha\\db_sql\\env\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.2.2)\n",
      "Installing collected packages: pycparser, w3lib, pyasn1, lxml, jmespath, cssselect, cffi, attrs, zope.interface, twisted-iocpsupport, requests-file, pyasn1-modules, parsel, itemadapter, incremental, hyperlink, filelock, cryptography, constantly, automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n",
      "Successfully installed PyDispatcher-2.0.7 Twisted-24.3.0 attrs-23.2.0 automat-22.10.0 cffi-1.16.0 constantly-23.10.4 cryptography-42.0.5 cssselect-1.2.0 filelock-3.13.3 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 lxml-5.1.0 parsel-1.9.0 protego-0.3.0 pyOpenSSL-24.1.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycparser-2.21 queuelib-1.6.2 requests-file-2.0.0 scrapy-2.11.1 service-identity-24.1.0 tldextract-5.1.2 twisted-iocpsupport-1.0.4 w3lib-2.1.2 zope.interface-6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python38\\python.exe: can't open file 'booking/booking_exloratory.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python booking/booking_exloratory.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
